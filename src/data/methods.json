[
    {
        "id": "mesonet",
        "name": "MesoNet",
        "description": "A compact facial video forgery detection network",
        "paperTitle": "MesoNet: a Compact Facial Video Forgery Detection Network",
        "paperURL": "https://arxiv.org/abs/1809.00888",
        "codeURL": "https://github.com/DariusAf/MesoNet",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "lip-shape",
        "name": "Lip Shape Analysis",
        "description": "Analyzing lip shape for face forgery detection",
        "paperTitle": "Lips Don't Lie: A Generalisable and Robust Approach to Face Forgery Detection",
        "paperURL": "https://openaccess.thecvf.com/content/CVPR2021/papers/Haliassos_Lips_Dont_Lie_A_Generalisable_and_Robust_Approach_To_Face_CVPR_2021_paper.pdf",
        "codeURL": "unavailable",
        "why": [
            "deepfake",
            "deepfake-video",
            "reenactment"
        ],
        "where": [
            "human",
            "human-face",
            "human-mouth"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ]
    },
    {
        "id": "blood-flow",
        "name": "Blood Flow Analysis",
        "description": "Analyzing blood flow patterns for deepfake detection",
        "paperTitle": "DeepRhythm: Exposing DeepFakes with Attentional Visual Rhythms",
        "paperURL": "https://dl.acm.org/doi/10.1145/3394171.3413707",
        "codeURL": "unavailable",
        "why": [
            "deepfake",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ]
    },
    {
        "id": "eye-blinking",
        "name": "Eye Blinking Analysis",
        "description": "Detecting deepfakes by analyzing eye blinking patterns",
        "paperTitle": "Exposing fake videos with defective eye behavior",
        "paperURL": "https://arxiv.org/pdf/1806.02877.pdf",
        "codeURL": "unavailable",
        "why": [
            "deepfake",
            "deepfake-video",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face",
            "human-eyes"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ]
    },
    {
        "id": "face-xray",
        "name": "Face X-ray",
        "description": "Detecting face forgeries using blending artifacts",
        "paperTitle": "Face X-Ray for More General Face Forgery Detection",
        "paperURL": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Face_X-Ray_for_More_General_Face_Forgery_Detection_CVPR_2020_paper.pdf",
        "codeURL": "https://github.com/biai0755/Face-Xray",
        "why": [
            "deepfake",
            "deepfake-image",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "blending-artifacts"
        ]
    },
    {
        "id": "ela",
        "name": "Error Level Analysis (ELA)",
        "description": "Detecting image manipulation using compression artifacts",
        "paperTitle": "",
        "paperURL": "",
        "codeURL": "",
        "why": [
            "image-manipulation",
            "manual-forgery"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "compression-artifacts"
        ]
    },
    {
        "id": "head-pose",
        "name": "Head Pose Inconsistency",
        "description": "Detecting deepfakes by inconsistent head poses",
        "paperTitle": "Exposing DeepFake Videos By Detecting Face Warping Artifacts",
        "paperURL": "https://ieeexplore.ieee.org/document/8683164",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ],
        "deepLearning": false
    },
    {
        "id": "cornea-reflection",
        "name": "Cornea Reflection Analysis",
        "description": "Analyzing cornea reflections for synthetic face detection",
        "paperTitle": "Exposing DeepFake Videos By Detecting Inconsistent Corneal Specular Reflections",
        "paperURL": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414582",
        "codeURL": "",
        "why": [
            "synthetic-image"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "structural"
        ],
        "deepLearning": false
    },
    {
        "id": "f3net",
        "name": "F3Net",
        "description": "Face Forgery Detection Network in Frequency Domain",
        "paperTitle": "F3Net: Fusion, FeedForward and Frequency Domain Filtering for Robust Deepfake Detection",
        "paperURL": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570086.pdf",
        "codeURL": "https://github.com/neverandu/F3Net",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "frequency"
        ]
    },
    {
        "id": "srm",
        "name": "Steganalysis Rich Model (SRM)",
        "description": "Detecting face manipulation using steganalysis features",
        "paperTitle": "Steganalysis Rich Models for Steganalysis of Digital Images",
        "paperURL": "https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/2813.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "manual-forgery"
        ],
        "where": [
            "human",
            "human-face",
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "noise-artifacts"
        ]
    },
    {
        "id": "spsl",
        "name": "Spatial-Phase Shallow Learning",
        "description": "Deepfake detection in the frequency domain",
        "paperTitle": "Spatial-Phase Shallow Learning: Rethinking Face Forgery Detection in Frequency Domain",
        "paperURL": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Spatial-Phase_Shallow_Learning_Rethinking_Face_Forgery_Detection_in_Frequency_Domain_CVPR_2021_paper.pdf",
        "codeURL": "https://github.com/RUC-Air-Lab/SPSL",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "frequency"
        ]
    },
    {
        "id": "ffd",
        "name": "Facial Forgery Detection",
        "description": "Detecting various types of facial forgeries",
        "paperTitle": "On the Detection of Digital Face Manipulation",
        "paperURL": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Dang_On_the_Detection_of_Digital_Face_Manipulation_CVPR_2020_paper.pdf",
        "codeURL": "https://github.com/binghamton-tgs/FFD",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap",
            "synthetic-video"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "ucf",
        "name": "Uncovering Common Features (UCF)",
        "description": "Generalizable deepfake detection by uncovering common features",
        "paperTitle": "UCF: Uncovering Common Features for Generalizable Deepfake Detection",
        "paperURL": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.pdf",
        "codeURL": "https://github.com/bluelaten/UCF",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "capsule",
        "name": "Capsule Networks for Deepfake Detection",
        "description": "Using capsule networks to detect deepfakes",
        "paperTitle": "Exposing Deep Fakes Using Inconsistent Head Poses",
        "paperURL": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682602",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "dsp-fwa",
        "name": "DSP-FWA",
        "description": "Detecting face warping artifacts in deepfakes",
        "paperTitle": "Exposing DeepFake Videos By Detecting Face Warping Artifacts",
        "paperURL": "https://openaccess.thecvf.com/content_CVPRW_2019/papers/Media%20Forensics/Li_Exposing_DeepFake_Videos_By_Detecting_Face_Warping_Artifacts_CVPRW_2019_paper.pdf",
        "codeURL": "https://github.com/danmohaha/DSP-FWA",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "core",
        "name": "CORE",
        "description": "Consistent representation learning for face forgery detection",
        "paperTitle": "CORE: COnsistent REpresentation Learning for Face Forgery Detection",
        "paperURL": "https://openaccess.thecvf.com/content/CVPR2022W/WMF/papers/Ni_CORE_COnsistent_REpresentation_Learning_for_Face_Forgery_Detection_CVPRW_2022_paper.pdf",
        "codeURL": "https://github.com/nimaicn/CORE",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "recce",
        "name": "RECCE",
        "description": "End-to-end reconstruction-classification for face forgery detection",
        "paperTitle": "End-to-End Reconstruction-Classification Learning for Face Forgery Detection",
        "paperURL": "https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_End-to-End_Reconstruction-Classification_Learning_for_Face_Forgery_Detection_CVPR_2022_paper.pdf",
        "codeURL": "https://github.com/GlassyXu/RECCE",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "phoneme-viseme",
        "name": "Phoneme-Viseme Mismatch",
        "description": "Detecting deepfakes from audio-visual mismatches",
        "paperTitle": "Detecting Deep-Fake Videos From Phoneme-Viseme Mismatches",
        "paperURL": "https://openaccess.thecvf.com/content_CVPRW_2020/papers/w39/Agarwal_Detecting_Deep-Fake_Videos_From_Phoneme-Viseme_Mismatches_CVPRW_2020_paper.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video",
            "reenactment"
        ],
        "where": [
            "human",
            "human-face",
            "human-mouth"
        ],
        "what": [
            "temporal",
            "temporal-physiology",
            "temporal-synchronization"
        ]
    },
    {
        "id": "face-background-noise",
        "name": "Face vs Background Noise Differences",
        "description": "Detecting deepfakes by analyzing noise differences between face and background regions",
        "paperTitle": "Detection of face manipulation by inconsistent imaging noise",
        "paperURL": "https://www.sciencedirect.com/science/article/pii/S2666281722000762",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face",
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "noise-artifacts"
        ]
    },
    {
        "id": "edge-information",
        "name": "Edge Region Feature Extraction",
        "description": "Using edge information for generalized facial manipulation detection",
        "paperTitle": "Generalized Facial Manipulation Detection With Edge Region Feature Extraction",
        "paperURL": "https://openaccess.thecvf.com/content/WACV2022/papers/Kim_Generalized_Facial_Manipulation_Detection_With_Edge_Region_Feature_Extraction_WACV_2022_paper.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face",
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "mantra-net",
        "name": "ManTra-Net",
        "description": "Manipulation tracing network for image forgery localization",
        "paperTitle": "ManTra-Net: Manipulation Tracing Network for Detection and Localization of Image Forgeries With Anomalous Features",
        "paperURL": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_ManTra-Net_Manipulation_Tracing_Network_for_Detection_and_Localization_of_Image_CVPR_2019_paper.pdf",
        "codeURL": "https://github.com/pxb615/ManTra-Net",
        "why": [
            "image-splicing",
            "image-removal",
            "image-enhancement",
            "copy-move"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "model-fingerprints",
        "name": "Model Fingerprints",
        "description": "Detecting synthetic images using model fingerprints",
        "paperTitle": "Model Fingerprints for Deep Image Forgery Detection and Localization",
        "paperURL": "https://arxiv.org/pdf/2211.00680.pdf",
        "codeURL": "",
        "why": [
            "synthetic-image"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "frequency"
        ]
    },
    {
        "id": "prnu",
        "name": "Photo Response Non-Uniformity (PRNU)",
        "description": "Detecting image manipulation using sensor noise patterns",
        "paperTitle": "Detecting DeepFakes using Camera Model Fingerprints",
        "paperURL": "https://dl.acm.org/doi/pdf/10.1145/3437880.3460400",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap",
            "manual-forgery"
        ],
        "where": [
            "human",
            "human-face",
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "noise-artifacts"
        ],
        "deepLearning": false
    },
    {
        "id": "image-stats",
        "name": "Image Statistics Analysis",
        "description": "Analyzing image statistics for forgery detection",
        "paperTitle": "",
        "paperURL": "",
        "codeURL": "",
        "why": [
            "deepfake",
            "manual-forgery",
            "synthetic-image"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "frequency"
        ],
        "deepLearning": false
    },
    {
        "id": "metadata-analysis",
        "name": "Metadata Analysis",
        "description": "Analyzing file metadata for forgery detection",
        "paperTitle": "",
        "paperURL": "",
        "codeURL": "",
        "why": [
            "deepfake",
            "manual-forgery",
            "synthetic-image"
        ],
        "where": [
            "file"
        ],
        "what": [
            "file-structure"
        ],
        "deepLearning": false
    },
    {
        "id": "behavior-analysis",
        "name": "Behavior Analysis",
        "description": "Detecting deepfakes by analyzing facial expressions and head movements",
        "paperTitle": "Face Biometrics in the Wild: Multi-view Facial Deception Detection",
        "paperURL": "https://farid.berkeley.edu/downloads/publications/wifs20.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "temporal",
            "temporal-behavior"
        ]
    },
    {
        "id": "clip-based",
        "name": "CLIP-based Detection",
        "description": "Detecting synthetic images using CLIP features",
        "paperTitle": "CLIP-Based Detection of Image Manipulations for Generative Forgeries",
        "paperURL": "https://arxiv.org/abs/2312.00195",
        "codeURL": "",
        "why": [
            "synthetic-image"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    }
]