[
    {
        "id": "mesonet",
        "name": "MesoNet",
        "description": "This method uses a deep learning approach for detecting face tampering in videos, specifically targeting Deepfake and Face2Face techniques. It uses two neural network architectures, Meso-4 and MesoInception-4, which are designed with a small number of layers to focus on mesoscopic properties of images. These networks are trained and tested on datasets created from online videos and demonstrate high detection rates, with over 98% accuracy for Deepfake and 95% for Face2Face. The technique emphasizes the efficiency and low computational cost of the proposed methods, making them suitable for real-world applications.",
        "paperTitle": "MesoNet: a Compact Facial Video Forgery Detection Network",
        "paperURL": "https://arxiv.org/abs/1809.00888",
        "codeURL": "https://github.com/DariusAf/MesoNet",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "lip-shape",
        "name": "Lip Shape Analysis",
        "description": "The technique focuses on detecting deepfake videos by analyzing inconsistencies in mouth movements. It involves two main stages: pretraining a spatio-temporal network on lipreading to learn rich representations related to natural mouth motion, and then finetuning the network on real and forged data to detect fake videos based on mouth movements without overfitting to low-level, manipulation-specific artifacts. LipForensics achieves state-of-the-art generalization to unseen forgery types and robustness to common corruptions, making it effective for real-world face forgery detection.",
        "paperTitle": "Lips Don't Lie: A Generalisable and Robust Approach to Face Forgery Detection",
        "paperURL": "https://openaccess.thecvf.com/content/CVPR2021/papers/Haliassos_Lips_Dont_Lie_A_Generalisable_and_Robust_Approach_To_Face_CVPR_2021_paper.pdf",
        "codeURL": "unavailable",
        "why": [
            "deepfake",
            "deepfake-video",
            "reenactment"
        ],
        "where": [
            "human",
            "human-face",
            "human-mouth"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ]
    },
    {
        "id": "blood-flow",
        "name": "Blood Flow Analysis",
        "description": "The methodology, known as DeepRhythm, leverages the concept of remote visual photoplethysmography (PPG) to detect DeepFakes by analyzing the heartbeat rhythms in video frames. It employs a motion-magnified spatial-temporal representation (MMSTR) to highlight the heart rhythm signals and uses a dual-spatial-temporal attention network to adapt to dynamic face changes and various fake types. This approach is robust against different datasets and challenging degradations, making it a powerful tool for DeepFake detection.",
        "paperTitle": "DeepRhythm: Exposing DeepFakes with Attentional Visual Rhythms",
        "paperURL": "https://dl.acm.org/doi/10.1145/3394171.3413707",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ]
    },
    {
        "id": "eye-blinking",
        "name": "Eye Blinking Analysis",
        "description": "The methodology for detecting manipulated media focuses on analyzing eye blinking patterns. It employs a deep learning model that combines a convolutional neural network (CNN) with a recursive neural network (RNN). Unlike frame-by-frame analysis, this approach considers the temporal correlation of eye blinking, improving detection accuracy. The Long-term Recurrent Convolutional Networks (LRCN) model is used for training and testing, leading to better identification of manipulated videos.",
        "paperTitle": "Exposing fake videos with defective eye behavior",
        "paperURL": "https://arxiv.org/pdf/1806.02877.pdf",
        "codeURL": "unavailable",
        "why": [
            "deepfake",
            "deepfake-video",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face",
            "human-eye"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ]
    },
    {
        "id": "face-xray",
        "name": "Face X-ray",
        "description": "The technique focuses on detecting manipulated media through a novel image representation called 'face X-ray'. It identifies whether an image is a composite of two sources by revealing blending boundaries in forged images and the absence of blending in real ones. This method assumes a common step in most face manipulation methods: blending an altered face into a background image. The face X-ray is a greyscale image that can be computed from the input, determining the authenticity of the image and pinpointing the blending boundary if present. This approach is general, not relying on specific artifacts of face manipulation techniques, and can be trained using only real images to effectively detect forgeries produced by unseen manipulation methods.",
        "paperTitle": "Face X-Ray for More General Face Forgery Detection",
        "paperURL": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Face_X-Ray_for_More_General_Face_Forgery_Detection_CVPR_2020_paper.pdf",
        "codeURL": "https://github.com/biai0755/Face-Xray",
        "why": [
            "deepfake",
            "deepfake-image",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "blurring-artifacts"
        ]
    },
    {
        "id": "ela",
        "name": "Error Level Analysis (ELA)",
        "description": "Error Level Analysis (ELA) is a technique used to detect image forgeries by analyzing the levels of compression errors within an image. When an image is saved in a lossy format like JPEG, it introduces a consistent level of compression artifacts across the image. ELA works by re-saving the image at a known error rate and then comparing the original error level to the re-saved error level. If a section of the image has been tampered with, it will have a different error level than the untouched parts, revealing potential areas of forgery. This method is particularly effective in identifying areas that have been copied and pasted within the same image, as these manipulations tend to introduce inconsistencies in the error levels.",
        "paperTitle": "",
        "paperURL": "",
        "codeURL": "",
        "why": [
            "manual-forgery",
            "manual-forgery-image"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "compression-artifacts"
        ]
    },
    {
        "id": "head-pose",
        "name": "Head Pose Inconsistency",
        "description": "The methodology involves a multi-step process that starts with the collection of a diverse dataset of media files. These files are then analyzed using advanced machine learning algorithms, which have been trained to recognize patterns and inconsistencies typical of manipulated content. The system also incorporates cross-referencing techniques to compare media against verified sources, enhancing its accuracy in identifying alterations. This approach ensures a robust and reliable detection of manipulated media, contributing to the integrity of digital content.",
        "paperTitle": "Exposing Deep Fakes Using Inconsistent Head Poses",
        "paperURL": "https://ieeexplore.ieee.org/document/8683164",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ],
        "deepLearning": false
    },
    {
        "id": "cornea-reflection",
        "name": "Cornea Reflection Analysis",
        "description": "The technique involves analyzing the corneal specular highlights (the reflections of light sources on the cornea) between the two eyes in an image. In real human faces, the corneal specular highlights tend to be consistent between the two eyes due to the physical constraints of the eye anatomy and the portrait setting. However, in faces generated by generative adversarial network (GAN) models, the corneal specular highlights can exhibit inconsistencies between the two eyes, as the GAN models lack an understanding of human face physiology. An automated method is used to extract and compare the corneal specular highlights from the two eyes, and the similarity score (measured by intersection-over-union) is used as a feature to distinguish real faces from GAN-synthesized ones.",
        "paperTitle": "Exposing DeepFake Videos By Detecting Inconsistent Corneal Specular Reflections",
        "paperURL": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414582",
        "codeURL": "",
        "why": [
            "synthetic-media",
            "synthetic-image"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-structural"
        ],
        "deepLearning": false
    },
    {
        "id": "f3net",
        "name": "F3Net",
        "description": "The key methodology uses a two-stream collaborative learning framework that leverages frequency-aware clues. The first stream performs frequency-aware decomposition to discover subtle forgery patterns in different frequency bands, while the second stream extracts local frequency statistics to capture statistical discrepancies between real and forged media. These two frequency-aware clues are then progressively fused through a cross-attention module, enabling the detection network to effectively mine both low-level frequency patterns and high-level frequency-based semantics for robust manipulation artifact identification, especially for low-quality compressed media where conventional spatial-based approaches struggle.",
        "paperTitle": "F3Net: Fusion, FeedForward and Frequency Domain Filtering for Robust Deepfake Detection",
        "paperURL": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570086.pdf",
        "codeURL": "https://github.com/neverandu/F3Net",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "spatial-frequency"
        ]
    },
    {
        "id": "srm",
        "name": "Steganalysis Rich Model (SRM)",
        "description": "The technique focuses on the detection and grounding of multi-modal media manipulation, particularly addressing fake media in both visual and textual forms. The methodology, named Detecting and Grounding Multi-Modal Media Manipulation (DGM^4), aims to detect the authenticity of multi-modal media and pinpoint the manipulated content within image-text pairs. It introduces a novel model called HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER), which employs manipulation-aware contrastive learning and modality-aware cross-attention mechanisms to discern and localize subtle forgeries across different modalities.",
        "paperTitle": "Steganalysis Rich Models for Steganalysis of Digital Images",
        "paperURL": "https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/2813.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "manual-forgery",
            "manual-forgery-image"
        ],
        "where": [
            "human",
            "human-face",
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "noise-artifacts"
        ]
    },
    {
        "id": "spsl",
        "name": "Spatial-Phase Shallow Learning",
        "description": "The key idea of analytic is to leverage the phase spectrum of the input image, in addition to the spatial domain information, to capture the artifacts introduced by the up-sampling operations commonly used in face manipulation techniques. The authors observe that up-sampling leads to more prominent changes in the phase spectrum compared to the amplitude spectrum, and the CNN-based SPSL model is designed to exploit these phase-based cues. Furthermore, the authors reduce the receptive field of the network by using a shallow architecture, which helps focus on local texture features rather than high-level semantics, further boosting the generalization ability of the detector. The method is evaluated on several benchmark face forgery datasets, and it achieves state-of-the-art performance, especially in cross-dataset testing scenarios, demonstrating strong transferability. The main strength of SPSL is its ability to generalize to unseen face forgery techniques by leveraging the frequency domain information, but it may be limited to detecting forgeries that rely on up-sampling as a key step.",
        "paperTitle": "Spatial-Phase Shallow Learning: Rethinking Face Forgery Detection in Frequency Domain",
        "paperURL": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Spatial-Phase_Shallow_Learning_Rethinking_Face_Forgery_Detection_in_Frequency_Domain_CVPR_2021_paper.pdf",
        "codeURL": "https://github.com/RUC-Air-Lab/SPSL",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "spatial-frequency"
        ]
    },
    {
        "id": "ffd",
        "name": "Facial Forgery Detection",
        "description": "The methodology focuses specifically on four types of facial forgeries: expression swap, identity swap, attribute manipulation, and entire face synthesis. The key component is an attention-based layer that can be inserted into any CNN-based backbone network. This attention mechanism helps the network focus on the informative regions for fake face detection and also localizes the manipulated facial regions. The proposed approach outperforms state-of-the-art methods, especially in detecting partially manipulated faces. However, the method is specialized for facial imagery and may not generalize well to other types of media manipulation such as audio or video. The diversity of the collected training dataset is a strength of the work, but the attention map estimation could potentially be further improved for more accurate localization of manipulated regions.",
        "paperTitle": "On the Detection of Digital Face Manipulation",
        "paperURL": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Dang_On_the_Detection_of_Digital_Face_Manipulation_CVPR_2020_paper.pdf",
        "codeURL": "https://github.com/binghamton-tgs/FFD",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap",
            "synthetic-image"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "ucf",
        "name": "Uncovering Common Features (UCF)",
        "description": "The the analytic uses a novel disentanglement framework for generalizable deepfake detection, focusing on detecting forged facial images. The key idea is to disentangle the input image into three distinct components: forgery-irrelevant features (content), method-specific forgery features, and common forgery features. By utilizing only the common forgery features for detection and employing a multi-task learning strategy, the framework aims to overcome the overfitting issues of existing detectors to forgery-irrelevant features and method-specific patterns. The strength of this approach is its ability to generalize well to unseen forgery techniques, as demonstrated by the superior performance on several benchmark datasets. However, the weakness is that it is specifically designed for detecting forged facial images and may not directly apply to other types of media manipulation.",
        "paperTitle": "UCF: Uncovering Common Features for Generalizable Deepfake Detection",
        "paperURL": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.pdf",
        "codeURL": "https://github.com/bluelaten/UCF",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "capsule",
        "name": "Capsule Networks for Deepfake Detection",
        "description": "The analytic uses a capsule network to detect forged images and videos across a wide range of forgery scenarios, including replay attacks and computer-generated images/videos. The key strengths of the method are: 1) It can handle various types of media manipulation, from replay attacks using printed images/recorded videos to fully computer-generated content, unlike many existing methods that are targeted at specific types of attacks. 2) It leverages the dynamic routing algorithm in capsule networks to effectively capture the hierarchical relationships between features, which boosts detection performance on complex and high-quality forgeries. The paper demonstrates the method's superior performance compared to state-of-the-art techniques on several benchmark datasets. A potential weakness is that it has only been evaluated on limited datasets, and its robustness to more sophisticated adversarial attacks is not yet clear. Overall, the Capsule-Forensics approach shows promise as a more general-purpose media manipulation detection tool.",
        "paperTitle": "Exposing Deep Fakes Using Inconsistent Head Poses",
        "paperURL": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682602",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "dsp-fwa",
        "name": "DSP-FWA",
        "description": "The analytic uses a deep learning-based method for detecting deepfake videos. The key idea is that current deepfake algorithms can only generate faces of limited resolutions, which then need to be warped to match the original faces in the source video. This warping process leaves distinctive artifacts that can be captured by convolutional neural networks (CNNs). The method does not require training on actual deepfake videos, which can be time-consuming and resource-intensive. Instead, it generates negative training examples by simulating the face warping process directly. This makes the method more efficient and robust compared to approaches that rely on training on specific deepfake datasets. The method is evaluated on two deepfake video datasets and shown to outperform state-of-the-art techniques. Its main strength is the ability to detect deepfake videos without requiring access to the actual deepfake generation process, though its performance may be affected by additional post-processing applied to the videos.",
        "paperTitle": "Exposing DeepFake Videos By Detecting Face Warping Artifacts",
        "paperURL": "https://openaccess.thecvf.com/content_CVPRW_2019/papers/Media%20Forensics/Li_Exposing_DeepFake_Videos_By_Detecting_Face_Warping_Artifacts_CVPRW_2019_paper.pdf",
        "codeURL": "https://github.com/danmohaha/DSP-FWA",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "core",
        "name": "CORE",
        "description": "CORE uses a shared encoder network to extract representations from two randomly augmented views of the input image, and then explicitly enforces consistency between these representations through a consistency loss. This approach aims to capture more intrinsic forgery evidence, as opposed to just relying on manipulated artifacts. The method is demonstrated to perform favorably compared to state-of-the-art face forgery detection approaches on multiple benchmarks, both in-dataset and cross-dataset. A key strength is that CORE can be flexibly integrated with existing methods. However, a potential weakness is that the approach may not be as effective for low-quality videos, as it does not explicitly model frequency-domain features like some other methods.",
        "paperTitle": "CORE: COnsistent REpresentation Learning for Face Forgery Detection",
        "paperURL": "https://openaccess.thecvf.com/content/CVPR2022W/WMF/papers/Ni_CORE_COnsistent_REpresentation_Learning_for_Face_Forgery_Detection_CVPRW_2022_paper.pdf",
        "codeURL": "https://github.com/nimaicn/CORE",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "recce",
        "name": "RECCE",
        "description": "The analytic focuses on media manipulation in facial images and videos. It introduces a reconstruction-classification learning approach that emphasizes common compact representations of genuine faces to enhance the detection of unknown forgery patterns. The framework's strengths include its ability to generalize to new forgery types and robustness against various perturbations. However, it may have weaknesses in scenarios where forgeries closely mimic the compact distribution of real samples, potentially challenging the model's discrimination capabilities.",
        "paperTitle": "End-to-End Reconstruction-Classification Learning for Face Forgery Detection",
        "paperURL": "https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_End-to-End_Reconstruction-Classification_Learning_for_Face_Forgery_Detection_CVPR_2022_paper.pdf",
        "codeURL": "https://github.com/GlassyXu/RECCE",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "phoneme-viseme",
        "name": "Phoneme-Viseme Mismatch",
        "description": "The analytic uses a forensic technique for detecting lip-sync deep-fake videos by exploiting phoneme-viseme mismatches. It focuses on the visemes associated with words starting with the sounds M, B, or P, which require the mouth to be completely closed. The paper shows that this mouth closure requirement is often violated in deep-fake videos, even if the manipulation is not visually apparent. The technique is evaluated on several datasets of deep-fake videos created using different synthesis methods, as well as some in-the-wild deep fakes. The authors demonstrate that this approach can achieve high detection accuracy, especially for longer video durations. However, the technique is most effective for detecting lip-sync deep fakes and may be less robust to other types of manipulations. Additionally, the automatic mouth open/closed classification can be sensitive to video quality degradation like recompression or resizing, making manual annotation more reliable in some cases.",
        "paperTitle": "Detecting Deep-Fake Videos From Phoneme-Viseme Mismatches",
        "paperURL": "https://openaccess.thecvf.com/content_CVPRW_2020/papers/w39/Agarwal_Detecting_Deep-Fake_Videos_From_Phoneme-Viseme_Mismatches_CVPRW_2020_paper.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video",
            "reenactment"
        ],
        "where": [
            "human",
            "human-face",
            "human-mouth"
        ],
        "what": [
            "temporal",
            "temporal-physiology",
            "temporal-synchronization"
        ]
    },
    {
        "id": "face-background-noise",
        "name": "Face vs Background Noise Differences",
        "description": "The analytic focuses on extracting and analyzing the forensic noise traces within the video frames, rather than relying solely on visual features for detection of deepfake videos. The key aspect of the methodology is a face-background strategy, where the model extracts and compares the noise traces between the face region and the background region of each frame using a Siamese network architecture and a similarity matrix, allowing it to effectively differentiate manipulated face areas from the unmodified background. This approach outperforms state-of-the-art computer vision-based methods in detecting high-quality and difficult-to-spot deepfake videos, and provides visual evidence of the detected manipulation by displaying the extracted forensic noise traces, though it may be less effective on low-resolution or heavily compressed footage and may not generalize well to other types of media manipulation beyond facial swapping.",
        "paperTitle": "Detection of face manipulation by inconsistent imaging noise",
        "paperURL": "https://www.sciencedirect.com/science/article/pii/S2666281722000762",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face",
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "noise-artifacts"
        ]
    },
    {
        "id": "edge-information",
        "name": "Edge Region Feature Extraction",
        "description": "A generalized and robust face manipulation detection method that extracts pixel-level color features from the edge regions of entire images and videos, including both the facial region and background, and uses a 3D-CNN classification model to interpret these features spatially and temporally across multiple frames. The key strengths of this approach are its ability to generalize well to unseen datasets and its robustness to various post-processing techniques like compression and resizing, though it is specialized for detecting facial manipulation and may not extend as well to other types of media beyond faces.",
        "paperTitle": "Generalized Facial Manipulation Detection With Edge Region Feature Extraction",
        "paperURL": "https://openaccess.thecvf.com/content/WACV2022/papers/Kim_Generalized_Facial_Manipulation_Detection_With_Edge_Region_Feature_Extraction_WACV_2022_paper.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face",
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "mantra-net",
        "name": "ManTra-Net",
        "description": "The analytic uses an end-to-end deep neural architecture designed for the detection and localization of image forgeries with anomalous features. It specializes in handling various known forgery types such as splicing, copy-move, removal, enhancement, and even unknown types, making it robust against a wide range of manipulations. The methodology involves a self-supervised learning task to classify 385 image manipulation types, formulating forgery localization as a local anomaly detection problem, and employing a novel LSTM solution to assess local anomalies. While it demonstrates generalizability and robustness, its limitations include potential failure in cases where an image is fully regenerated or highly contaminated with correlated noise, and when multiple regions are manipulated differently.",
        "paperTitle": "ManTra-Net: Manipulation Tracing Network for Detection and Localization of Image Forgeries With Anomalous Features",
        "paperURL": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_ManTra-Net_Manipulation_Tracing_Network_for_Detection_and_Localization_of_Image_CVPR_2019_paper.pdf",
        "codeURL": "https://github.com/pxb615/ManTra-Net",
        "why": [
            "manual-forgery",
            "manual-forgery-image"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "model-fingerprints",
        "name": "Model Fingerprints",
        "description": "The analytic focuses on the detection of synthetic images generated by diffusion models (DMs). The methodology involves analyzing the forensic traces left by DMs, comparing the performance of current detectors developed for GAN-generated images against these new synthetic images, and assessing their effectiveness in challenging conditions like social network scenarios where images undergo compression and resizing. The strength of this approach lies in its thorough examination of DM artifacts and the use of deep learning-based detectors. However, the main weakness is the difficulty in generalizing detectors to architectures not seen during training, and the performance drop when image quality is impaired by routine social media processing.",
        "paperTitle": "Model Fingerprints for Deep Image Forgery Detection and Localization",
        "paperURL": "https://arxiv.org/pdf/2211.00680.pdf",
        "codeURL": "",
        "why": [
            "synthetic-media",
            "synthetic-image"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "spatial-frequency"
        ]
    },
    {
        "id": "prnu",
        "name": "Photo Response Non-Uniformity (PRNU)",
        "description": "The analytic focuses on detecting deepfake videos using Photo Response Non-Uniformity (PRNU) patterns. PRNU-based detection specializes in identifying inconsistencies in the sensor noise of digital imaging devices, which can reveal manipulations in media files. The strength of this approach lies in its low computational cost and potential for generalization across different types of deepfakes. However, the paper acknowledges that PRNU-based methods cannot yet compete with state-of-the-art deep learning methods in terms of accuracy, and their effectiveness is impacted by factors such as face extraction parameters and video compression levels. The methodology is suggested to complement deep learning methods in hybrid detection schemes to improve overall detection performance.",
        "paperTitle": "Detecting DeepFakes using Camera Model Fingerprints",
        "paperURL": "https://dl.acm.org/doi/pdf/10.1145/3437880.3460400",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-image",
            "deepfake-video",
            "reenactment",
            "faceswap",
            "manual-forgery",
            "manual-forgery-image"
        ],
        "where": [
            "human",
            "human-face",
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level",
            "noise-artifacts"
        ],
        "deepLearning": false
    },
    {
        "id": "metadata-analysis",
        "name": "Metadata Analysis",
        "description": "Analyzing file metadata for forgery detection",
        "paperTitle": "",
        "paperURL": "",
        "codeURL": "",
        "why": [
            "deepfake",
            "manual-forgery",
            "synthetic-media"
        ],
        "where": [
            "file"
        ],
        "what": [
            "file-analysis",
            "file-metadata"
        ],
        "deepLearning": false
    },
    {
        "id": "behavior-analysis",
        "name": "Behavior Analysis",
        "description": "The analytic presents a forensic technique for detecting face-swap deep fakes in videos, which combines a static biometric based on facial recognition with a temporal, behavioral biometric based on facial expressions and head movements. The strength of this method lies in its ability to capture the unique spatiotemporal behavior of individuals, making it robust against laundering attacks and capable of generalizing across different datasets. However, it requires significant effort to create models for each individual and may struggle with lip-sync deep fakes where only the mouth has been modified. The technique is less vulnerable to counter-attacks and generalizes well to previously unseen deep fakes with previously unseen people.",
        "paperTitle": "Face Biometrics in the Wild: Multi-view Facial Deception Detection",
        "paperURL": "https://farid.berkeley.edu/downloads/publications/wifs20.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video",
            "reenactment",
            "faceswap"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "temporal",
            "temporal-behavior"
        ]
    },
    {
        "id": "clip-based",
        "name": "CLIP-based Detection",
        "description": "The analytic uses pre-trained vision-language models (VLMs), specifically focusing on the CLIP features to detect AI-generated images. It introduces a lightweight detection strategy that does not require extensive domain-specific training data. Instead, it uses a small set of example images from a single generative model to train a CLIP-based detector. This approach demonstrates strong generalization capabilities and robustness across various architectures, including recent commercial tools like Dalle-3, Midjourney v5, and Firefly. The method's strengths include its surprising generalization ability and high robustness to out-of-distribution data and impaired/laundered data. However, the original paper does not explicitly discuss potential weaknesses, which might include limitations in detecting more sophisticated manipulations or the need for further validation in diverse real-world scenarios.",
        "paperTitle": "CLIP-Based Detection of Image Manipulations for Generative Forgeries",
        "paperURL": "https://arxiv.org/abs/2312.00195",
        "codeURL": "",
        "why": [
            "synthetic-media",
            "synthetic-image"
        ],
        "where": [
            "scene"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    },
    {
        "id": "aural",
        "name": "Aural & Oral Dynamic",
        "description": "This analytic tracks the motion of the ear's outer regions (helix, tragus, and lobule) during speech and correlates it with mouth movements and audio signals. Desynchronization between the aural and oral signals can reveal lip-sync deep fakes where the mouth region has been synthesized without considering the natural ear motions.",
        "paperTitle": "Detecting Deep-Fake Videos from Aural and Oral Dynamics",
        "paperURL": "https://ieeexplore.ieee.org/document/9522902",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video"
        ],
        "where": [
            "human",
            "human-face",
            "human-ear"
        ],
        "what": [
            "temporal",
            "temporal-physiology"
        ]
    },
    {
        "id": "xceptionnet",
        "name": "XceptionNet",
        "description": "XceptionNet, initially designed for image classification, is adapted for deepfake detection by modifying its final layer and fine-tuning the network through pre-training and subsequent training epochs. The model, initialized with ImageNet weights, can detect deepfakes, especially the FaceForensics++ dataset proposed in the same paper.",
        "paperTitle": "FaceForensics++: Learning to Detect Manipulated Facial Images",
        "paperURL": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Rossler_FaceForensics_Learning_to_Detect_Manipulated_Facial_Images_ICCV_2019_paper.pdf",
        "codeURL": "",
        "why": [
            "deepfake",
            "deepfake-video",
            "deepfake-image"
        ],
        "where": [
            "human",
            "human-face"
        ],
        "what": [
            "spatial",
            "spatial-pixel-level"
        ]
    }
]